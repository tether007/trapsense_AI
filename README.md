# TrapSense AI - Wildlife Camera Trap Analysis Platform

<div align="center">

![TrapSense AI](https://img.shields.io/badge/TrapSense-AI-green?style=for-the-badge&logo=leaf)
![Python](https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python)
![React](https://img.shields.io/badge/React-19.1+-61DAFB?style=for-the-badge&logo=react)
![FastAPI](https://img.shields.io/badge/FastAPI-0.118+-009688?style=for-the-badge&logo=fastapi)

**AI-Powered Wildlife Camera Trap Analysis for Conservation Research**

*Automatically detect, classify, and organize thousands of camera trap images. Save time, protect wildlife, and combat poaching with intelligent image analysis.*

</div>

---

## Problem Statement

Wildlife researchers and conservationists face the monumental challenge of processing thousands of camera trap images manually. Traditional methods are:

- **Time-intensive**: Manual review of thousands of images takes weeks
- **Error-prone**: Human fatigue leads to missed detections and misclassifications  
- **Resource-heavy**: Requires large teams of trained personnel
- **Inefficient**: No systematic way to organize and analyze wildlife data

**TrapSense AI** revolutionizes this process by providing an intelligent, automated solution that processes camera trap images in real-time, delivering accurate wildlife detection and classification results instantly.

---

##  Our Solution

TrapSense AI is a comprehensive platform that combines cutting-edge computer vision with modern web technologies to deliver:

### Core Capabilities
- **Smart Detection**: AI automatically identifies animals, humans, and vehicles in camera trap images
- **Instant Classification**: Segregate valid wildlife photos from empty frames and false triggers
- **Real-time Processing**: Process thousands of images in minutes, not days
- **Interactive Dashboard**: Visualize wildlife distribution patterns with heatmaps and statistics
- **Batch Processing**: Upload entire folders while preserving organizational structure
- **Export Capabilities**: Download filtered results and metadata for further analysis

### Key Features
- **Two-Stage ML Pipeline**: Classification (blank/non-blank) followed by object detection
- **Geographic Visualization**: Interactive heatmaps showing wildlife distribution patterns
- **User Authentication**: Secure access with Clerk authentication
- **Cloud Storage**: Scalable S3 integration for image storage
- **Real-time Updates**: Live processing status and prediction results

---

##  System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   ML Pipeline   â”‚
â”‚   (React)       â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (PyTorch)     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Dashboard     â”‚    â”‚ â€¢ REST API      â”‚    â”‚ â€¢ YOLOv8        â”‚
â”‚ â€¢ Upload UI     â”‚    â”‚ â€¢ Auth (Clerk)  â”‚    â”‚ â€¢ Classificationâ”‚
â”‚ â€¢ Heatmaps      â”‚    â”‚ â€¢ Database      â”‚    â”‚ â€¢ Detection     â”‚
â”‚ â€¢ Statistics    â”‚    â”‚ â€¢ S3 Storage    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cloud Storage â”‚    â”‚   Database      â”‚    â”‚   Background    â”‚
â”‚   (AWS S3)      â”‚    â”‚   (SQLite)     â”‚    â”‚   Processing   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Image Storage â”‚    â”‚ â€¢ User Data     â”‚    â”‚ â€¢ Async Tasks  â”‚
â”‚ â€¢ Presigned URLsâ”‚    â”‚ â€¢ Media Records â”‚    â”‚ â€¢ ML Inference  â”‚
â”‚ â€¢ File Metadata â”‚    â”‚ â€¢ Predictions   â”‚    â”‚ â€¢ DB Updates   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Upload**: Users upload images via React frontend
2. **Storage**: Images stored in AWS S3 with presigned URLs
3. **Database**: Media records created in SQLite database
4. **Processing**: Background tasks trigger ML pipeline
5. **Classification**: YOLOv8 model classifies images as blank/non-blank
6. **Detection**: Non-blank images processed through object detection
7. **Results**: Predictions stored in database and displayed in dashboard
8. **Visualization**: Heatmaps and statistics generated from processed data

---

## Technology Stack

### Frontend
- **React 19.1+** - Modern UI framework with hooks and context
- **Vite** - Fast build tool and development server
- **Tailwind CSS** - Utility-first CSS framework for responsive design
- **Framer Motion** - Smooth animations and transitions
- **React Router** - Client-side routing
- **Leaflet** - Interactive maps for heatmap visualization
- **Clerk** - Authentication and user management
- **Axios** - HTTP client for API communication

### Backend
- **FastAPI** - High-performance Python web framework
- **SQLAlchemy** - Python SQL toolkit and ORM
- **SQLite** - Lightweight database for development
- **Pydantic** - Data validation using Python type annotations
- **Uvicorn** - ASGI server for FastAPI
- **Clerk Backend API** - Server-side authentication
- **Boto3** - AWS SDK for S3 integration

### Machine Learning
- **PyTorch** - Deep learning framework
- **Ultralytics YOLOv8** - State-of-the-art object detection
- **PIL (Pillow)** - Python Imaging Library
- **NumPy** - Numerical computing
- **Torchvision** - Computer vision utilities

### Infrastructure
- **AWS S3** - Cloud storage for images
- **Docker** - Containerization (optional)
- **Git** - Version control

---

## Project Structure

```
IIIT_M/
â”œâ”€â”€ frontend/                 # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ common/      # Shared components
â”‚   â”‚   â”‚   â””â”€â”€ layout/      # Layout components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ auth/            # Authentication components
â”‚   â”‚   â”œâ”€â”€ css/             # Stylesheets
â”‚   â”‚   â””â”€â”€ utils/           # Utility functions
â”‚   â”œâ”€â”€ public/              # Static assets
â”‚   â””â”€â”€ package.json         # Dependencies
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/             # API routes
â”‚   â”‚   â”œâ”€â”€ database/        # Database models and operations
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ml.py        # ML pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ s3.py        # S3 operations
â”‚   â”‚   â”‚   â””â”€â”€ worker.py    # Background processing
â”‚   â”‚   â”œâ”€â”€ routes/          # API endpoints
â”‚   â”‚   â””â”€â”€ utils/            # Utility functions
â”‚   â””â”€â”€ pyproject.toml       # Python dependencies
â”œâ”€â”€ ml/                      # Machine learning models
â”‚   â”œâ”€â”€ classifier/          # Classification model
â”‚   â””â”€â”€ detection/           # Object detection model
â””â”€â”€ README.md               # This file
```

---

## Getting Started

### Prerequisites
- Python 3.10+
- Node.js 18+
- AWS S3 bucket (for production)
- Clerk account (for authentication)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd IIIT_M
   ```

2. **Backend Setup**
   ```bash
   cd backend
   pip install -r requirements.txt
   # Or using uv (recommended)
   uv sync
   ```

3. **Frontend Setup**
   ```bash
   cd frontend
   npm install
   ```

4. **Environment Configuration**
   ```bash
   # Backend .env
   CLERK_SECRET_KEY=your_clerk_secret_key
   JWT_SECRET_KEY=your_jwt_secret
   AWS_ACCESS_KEY_ID=your_aws_access_key
   AWS_SECRET_ACCESS_KEY=your_aws_secret_key
   AWS_BUCKET_NAME=your_s3_bucket
   AWS_REGION=your_aws_region
   
   # Frontend .env
   VITE_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key
   VITE_API_BASE_URL=http://localhost:8000/api
   ```

### Running the Application

1. **Start the Backend**
   ```bash
   cd backend
   uvicorn src.app:app --reload --host 0.0.0.0 --port 8000
   ```

2. **Start the Frontend**
   ```bash
   cd frontend
   npm run dev
   ```

3. **Access the Application**
   - Frontend: http://localhost:5173
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

---

## ğŸ”§ API Endpoints

### Authentication
- `POST /api/users` - Create new user
- `GET /api/users/me` - Get current user

### Media Management
- `POST /api/media` - Upload single image
- `POST /api/media/batch` - Upload multiple images
- `GET /api/media` - Get user's media
- `GET /api/media/{id}` - Get specific media
- `GET /api/media/heatmap` - Get coordinates for heatmap

### Processing
- `GET /api/predictions/{id}` - Get ML predictions
- `POST /api/predictions/process/{id}` - Trigger processing

### Export
- `GET /api/media/export/csv` - Export as CSV
- `GET /api/media/export/zip` - Export as ZIP
- `GET /api/media/export/summary` - Get export statistics

---

##  Machine Learning Pipeline

### Two-Stage Processing

1. **Classification Stage**
   - Input: Raw camera trap image
   - Model: Custom YOLOv8 classification model
   - Output: "blank" or "non-blank" with confidence score
   - Purpose: Filter out empty frames and false triggers

2. **Detection Stage** (for non-blank images)
   - Input: Classified non-blank image
   - Model: YOLOv8 object detection model
   - Output: Bounding boxes, species identification, confidence scores
   - Purpose: Identify and classify wildlife species

### Model Architecture
- **Framework**: PyTorch with Ultralytics YOLOv8
- **Input Size**: 224x224 pixels (classification), variable (detection)
- **Preprocessing**: Image normalization, resizing, tensor conversion
- **Output**: JSON format with bounding boxes, classes, and confidence scores

---

## Dashboard Features

### Wildlife Heatmap
- Interactive map showing wildlife distribution patterns
- Geographic visualization of camera trap locations
- Heat intensity based on detection frequency
- Focused on Serengeti ecosystem for demonstration

### Statistics Dashboard
- **Animal Count**: Total detections by species
- **Non-blank Statistics**: Processing metrics and success rates
- **Export Capabilities**: Download filtered results and metadata
- **Real-time Updates**: Live processing status and results

### Upload Interface
- **Single File Upload**: Individual image processing
- **Batch Upload**: Multiple images with progress tracking
- **Folder Upload**: Preserve organizational structure
- **Preview System**: Full-screen image preview with predictions

---

##  Security & Authentication

- **Clerk Integration**: Secure user authentication and management
- **JWT Tokens**: Stateless authentication for API access
- **User Isolation**: Data segregation by authenticated users
- **Presigned URLs**: Secure S3 upload without exposing credentials
- **CORS Protection**: Cross-origin request security

---

##  Deployment

### Production Considerations
- **Database**: Migrate from SQLite to PostgreSQL for production
- **Storage**: AWS S3 for scalable image storage
- **Authentication**: Clerk for production-ready auth
- **Monitoring**: Add logging and error tracking
- **Scaling**: Consider containerization with Docker

### Environment Variables
```bash
# Production environment variables
DATABASE_URL=postgresql://user:pass@host:port/db
AWS_BUCKET_NAME=production-bucket
CLERK_SECRET_KEY=production_secret_key
```

---

## ğŸ¤ Contributing

We welcome contributions to improve TrapSense AI! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

##  Acknowledgments

- **Ultralytics** for the YOLOv8 framework
- **Clerk** for authentication services
- **AWS** for cloud storage infrastructure
- **React** and **FastAPI** communities for excellent documentation
- **Wildlife Conservation** organizations for inspiration and use cases

---

<div align="center">

**Built with â¤ï¸ for Wildlife Conservation**

*Empowering researchers to protect our planet's biodiversity through intelligent technology*

</div>
